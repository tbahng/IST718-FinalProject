{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HydrateTweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPLMgkTmt33q9RmkSSqehlX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbahng/IST718-FinalProject/blob/master/HydrateTweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vf71LDH9vDq_",
        "colab_type": "text"
      },
      "source": [
        "# Hydrate Open Source Twitter Chatter Tweet IDs\n",
        "* Of the 80M tweet IDs extracted from the Open Source Covid-19 Twitter Chatter data set, a sample will be extracted using the Twitter API for modeling.\n",
        "* The term 'hydrate' in the context of tweets mean to get the details respective to a list of tweet ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXle6IoLu4ZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "4990fb89-cb36-457c-dafb-ede0972af5a1"
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S11WH9lvuqD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "86cd0fcb-ec98-464a-9a79-501e28e4cb18"
      },
      "source": [
        "# set working directory + view files in directory\n",
        "import os\n",
        "#os.listdir('drive/Shared drives/IST718-Summer2020-Team')\n",
        "wd = 'drive/Shared drives/IST718-Summer2020-Team'\n",
        "os.listdir(wd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sample Colab Notebook.ipynb',\n",
              " '551982_1359228_bundle_archive.zip',\n",
              " 'Kaggle',\n",
              " 'Project Check in 1 Rubric.pdf',\n",
              " 'Project Check In 1 ROUGH DRAFT.docx',\n",
              " 'Group1-Section2-Week5ProjectCheckin-2020.docx',\n",
              " 'IST718-Team-Contact-Info.gdoc',\n",
              " 'Twitter',\n",
              " 'Download Open Resource Covid-19 Twitter Chatter Dataset.ipynb',\n",
              " 'coronavirus.png',\n",
              " 'COVID Literature Word Cloud.png',\n",
              " 'Project Check In 2 ROUGH DRAFT.docx',\n",
              " 'Group1-Section2-Week7ProjectCheckin-2020.docx',\n",
              " 'HydrateTweets.ipynb',\n",
              " 'Final Project Workbook .ipynb',\n",
              " 'Group Project 718 Literature Review.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnMO77IQ5GgE",
        "colab_type": "text"
      },
      "source": [
        "## Get Tweet IDs and Down-Sample\n",
        "* all IDs are for tweets created in 2020 in the english language.\n",
        "* down-sampling will be random draws from equal sized chunks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBfF4sauwOSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "0be2e96a-55cf-4e72-844d-f67284051a40"
      },
      "source": [
        "%%time\n",
        "# read extracted tweet ids, see 'Download Open Resource Covid-19 Twitter Chatter Dataset.ipynb'\n",
        "fname = wd + '/Twitter/tweet_ids/english2020.txt'\n",
        "with open(fname, 'r') as fin:\n",
        "  tweet_id_list = [line.rstrip('\\n') for line in fin]\n",
        "print(\"There are {:d} tweet ids in english language and created in 2020.\".format(len(tweet_id_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 81083863 tweet ids in english language and created in 2020.\n",
            "CPU times: user 19.9 s, sys: 8.21 s, total: 28.1 s\n",
            "Wall time: 34.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5BJkYyN7cOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to break list into chunks\n",
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "tweet_id_list_chunks = chunks(tweet_id_list, 1000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvfZcBSx7LcW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bb954c4d-e244-482d-c1c1-ccb3e52fa92d"
      },
      "source": [
        "%%time\n",
        "# down-sampling\n",
        "import random\n",
        "random.seed(11)\n",
        "#sample_size = 3000 # desired sample size\n",
        "#sample_size = 30000 # desired sample size\n",
        "sample_size = 300000 # desired sample size\n",
        "num_chunks = int(len(tweet_id_list) / 1000000) # rounded to closest integer\n",
        "chunk_draws = int(sample_size / num_chunks) # rounded average number of draws per chunk\n",
        "sample_list = [] # initialized list of sample ids\n",
        "for chunk in tweet_id_list_chunks:\n",
        "  random.shuffle(chunk)\n",
        "  sample_list_size = len(sample_list) # size of sample list in iteration\n",
        "  to_go = sample_size - sample_list_size\n",
        "  if to_go >= chunk_draws:\n",
        "    sample_list.extend(chunk[:chunk_draws])\n",
        "  else:\n",
        "    sample_list.extend(chunk[:to_go])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 10s, sys: 115 µs, total: 1min 10s\n",
            "Wall time: 1min 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJFhumbKBENM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a20a7aa-3765-4a09-8661-b5698b98031c"
      },
      "source": [
        "del tweet_id_list\n",
        "print(\"Sample size of tweet ids for hydration: {:d}\".format(len(sample_list)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample size of tweet ids for hydration: 300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5SDTSNG5OUr",
        "colab_type": "text"
      },
      "source": [
        "## Twitter API Keys and Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAIsJmPL0Xuc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get twitter keys\n",
        "# key dictionary has the following keys: CONSUMER_KEY, CONSUMER_SECRET, OAUTH_TOKEN, OAUTH_SECRET\n",
        "fname = 'drive/My Drive/IST 718/secret_twitter_key.txt'\n",
        "key_dict = {}\n",
        "with open(fname, 'r') as fin:\n",
        "  lines = [line.strip().split() for line in fin]\n",
        "  for line in lines:\n",
        "    key_dict[line[0]] = line[2].strip('\\'')\n",
        "    \n",
        "# assign these keys to variables\n",
        "CONSUMER_KEY = key_dict['CONSUMER_KEY']\n",
        "CONSUMER_SECRET = key_dict['CONSUMER_SECRET']\n",
        "OAUTH_TOKEN = key_dict['OAUTH_TOKEN']\n",
        "OAUTH_TOKEN_SECRET = key_dict['OAUTH_SECRET']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocRAkJL2xP23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
        "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
        "api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMhWUjOAE3bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "030e108f-b2ce-4985-e398-f1bc4e580601"
      },
      "source": [
        "# TEST with one ID\n",
        "id_of_tweet = sample_list[0] # single tweet id\n",
        "tweet = api.get_status(id_of_tweet)\n",
        "print(tweet.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "As no one knows how long #coronavirus stays active on inert surfaces, from shoes, clothing to controls, all bets ar… https://t.co/QClfIl77Zw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McEUhngNEe0c",
        "colab_type": "text"
      },
      "source": [
        "## Extract Tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dV1dyUIOWHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id_chunks = chunks(sample_list, 100) # break ids into chunks of 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEJTwkCU384m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "# function to get tweet data per id\n",
        "# accounts for rate limiting thresholds and will wait on rate limit\n",
        "def lookup_tweets(tweet_IDs, api):\n",
        "  id_chunks = chunks(tweet_IDs, 100) # break ids into chunks of 100\n",
        "  full_tweets = [] # initialize list of results\n",
        "  try:\n",
        "    for chunk in id_chunks:\n",
        "      full_tweets.extend(api.statuses_lookup(id_=chunk))\n",
        "      #time.sleep(60)\n",
        "    return full_tweets    \n",
        "  except tweepy.TweepError as e:\n",
        "    print(e)\n",
        "  print('Full tweets collected: {:d}'.format(len(full_tweets)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-JnAzV4EEhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "fcca1244-b149-42f2-de01-709c369628e0"
      },
      "source": [
        "%%time\n",
        "# execute\n",
        "results = lookup_tweets(sample_list, api)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Rate limit reached. Sleeping for: 82\n",
            "Rate limit reached. Sleeping for: 66\n",
            "Rate limit reached. Sleeping for: 55\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 36s, sys: 4.78 s, total: 1min 41s\n",
            "Wall time: 50min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5DA10AttIKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "fe5bcb41-fbb3-471d-8fc3-3ac4f814c637"
      },
      "source": [
        "tweet_sample = results[0]._json\n",
        "tweet_sample.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'quoted_status_id', 'quoted_status_id_str', 'quoted_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'possibly_sensitive', 'lang'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kshaekqoeQ9R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to extract dictionaries from list of results\n",
        "def getDict(lst):\n",
        "  out = [] # list of dictionaries\n",
        "  for item in lst:    \n",
        "    out.append({k: item._json[k] for k in ('id', 'created_at', 'text', 'coordinates', 'place')})\n",
        "  return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8AwpOO86xK9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "526a6fb0-396e-4de5-ac07-93a3831d4452"
      },
      "source": [
        "# extract relevant properties from tweets (i.e. 'created_at', 'id', 'text)\n",
        "tweets = getDict(results)\n",
        "print(\"There are {:d} tweets returned in the lookup.\".format(len(tweets)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 266473 tweets returned in the lookup.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0eqPfS57Rht",
        "colab_type": "text"
      },
      "source": [
        "Possible reason for difference with sample size might be deleted tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbjad9lfP-dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f497249b-e22f-4437-f9c4-9371ed33f1ae"
      },
      "source": [
        "# save to files\n",
        "import json\n",
        "#fname = wd + '/Twitter/english2020_sample3k.json' # 3k sample\n",
        "#fname = wd + '/Twitter/english2020_sample30k.json' # 30k sample\n",
        "fname = wd + '/Twitter/english2020_sample300k.json' # 300k sample\n",
        "with open(fname, 'w') as fout:\n",
        "  json.dump(tweets, fout)\n",
        "print(\"Results saved to {:s}\".format(fname))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results saved to drive/Shared drives/IST718-Summer2020-Team/Twitter/english2020_sample300k.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aW4Xva99fGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}